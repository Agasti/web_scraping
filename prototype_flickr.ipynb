{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, textwrap, time, json, re, requests, random, datetime, copy\n",
    "from datetime import datetime as dt\n",
    "from copy import deepcopy\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "global driver, params, AFTER_DATE ,BEFORE_DATE ,COURTESY_SLEEP ,PHOTOS_PER_PAGE ,VERBOSE ,TEST ,DUMP_PATH ,ADD_EXTRAS, HEADLESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "AFTER_DATE = dt.fromtimestamp(1570579058.0)\n",
    "BEFORE_DATE = dt.fromtimestamp(1577592826.384834)\n",
    "PHOTOS_PER_PAGE =  500\n",
    "VERBOSE =  4\n",
    "DUMP_PATH = './'\n",
    "TEST = True\n",
    "ADD_EXTRAS = 'url_o,original_format,date_taken,date_upload,geo'\n",
    "HEADLESS = True\n",
    "COURTESY_SLEEP = \"0, 0.000000001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=textwrap.dedent('''\\\n",
    "        scrape JSONs containing photos from flickr\n",
    "         '''))\n",
    "\n",
    "parser.add_argument(\"-a\", \"--after_date\", help=\"Start date (in unix timestamp format). Defaults to yesterday\", type=float, default=dt.now().timestamp() - (30 * 24 * 3600))\n",
    "parser.add_argument(\"-b\", \"--before_date\", help=\"End date (in unix timestamp format). Defaults to now\", type=float, default=dt.now().timestamp())\n",
    "parser.add_argument(\"-s\", \"--courtesy_sleep\", help=\"Range (in string format) from which a random value will be chosen to sleep randomly. example: '1.3, 2.7'\", type=str, default=\"1.3, 2.7\")\n",
    "parser.add_argument(\"-n\", \"--photos_per_page\", help=\"Photos per file. Default is 500 which is the maximum\", type=int, default=500)\n",
    "parser.add_argument(\"-v\", \"--verbose\", help=\"increase output verbosity\", action=\"count\", default=0)\n",
    "parser.add_argument(\"-p\", \"--dump_path\", help=\"Path where to dump json files\", type=str, default='./')\n",
    "parser.add_argument(\"-t\", \"--test\", help=\"test mode\", action='store_true')\n",
    "parser.add_argument(\"-w\", \"--webdriver\", help=\"Turn off headless mode for on the chrome webdriver\", action='store_false')\n",
    "parser.add_argument(\"-x\", \"--add_extras\", help=\"extra json fields to request. Defaults to 'url_o,original_format,date_taken,date_upload,geo'\", type=str, default=\"url_o,original_format,date_taken,date_upload,geo\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "args.__dict__['HEADLESS'] = args.webdriver\n",
    "\n",
    "# ansigning global variables from cmdline args for easy typing\n",
    "for each in args.__dict__: globals()[each.upper()] = args.__dict__[each]\n",
    "\n",
    "# making sure the dates are in datetime format\n",
    "for each in [\"AFTER_DATE\", \"BEFORE_DATE\"]:\n",
    "    if type(each) != type(dt.now()):\n",
    "        try:\n",
    "            globals()[each] = dt.fromtimestamp(globals()[each])\n",
    "        except Exception as e:\n",
    "            print(f\"please make sure the dates entered are in unix timestamps format: {e}\")\n",
    "\n",
    "# printing parameters for easy debugging\n",
    "if VERBOSE >=3:\n",
    "    print(\"\".ljust(120, \"_\") + \"\\nscript parameters\")\n",
    "    for each in args.__dict__:\n",
    "        print(f\"{each.upper()}: {args.__dict__[each]}\")\n",
    "    print(\"\".ljust(120, \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "    \n",
    "COURTESY_SLEEP = [float(COURTESY_SLEEP.split(',')[0]) , float(COURTESY_SLEEP.split(',')[1])]\n",
    "if TEST and VERBOSE > 3: COURTESY_SLEEP = [0, 0.000000001]\n",
    "\n",
    "\n",
    "DATA_PATH = ('./test/' if TEST else DUMP_PATH)\n",
    "\n",
    "params = {\n",
    "    \"sort\" : \"relevance\",\n",
    "    \"parse_tags\" : \"1\",\n",
    "    \"content_type\" : \"7\",\n",
    "    \"lang\": \"en-US\",\n",
    "    \"has_geo\" :\"1\",\n",
    "    \"media\" : \"photos\",\n",
    "    \"view_all\" : \"1\",\n",
    "    \"text\" : \"clouds\",\n",
    "    \"viewerNSID\": \"\",\n",
    "    \"method\" : \"flickr.photos.search\",\n",
    "    \"csrf\" : \"\",\n",
    "    \"format\" : \"json\",\n",
    "    \"hermes\" : \"1\",\n",
    "    \"hermesClient\" : \"1\",\n",
    "    \"nojsoncallback\" : \"1\",\n",
    "    \"geo_context\": '2', # 0: all , 1: indoors, 2 : outdoors\n",
    "    \"privacy_filter\" : 1\n",
    "}\n",
    "\n",
    "privacy_filters = '''\n",
    "\"public photos\" : '1',\n",
    "\"private photos visible to friends\" : '2',\n",
    "\"private photos visible to family\" : '3',\n",
    "\"private photos visible to friends & family\": '4',\n",
    "\"completely private photos\" : '5'\n",
    "'''\n",
    "\n",
    "FLICKR = 'https://flickr.com/search/'\n",
    "TAGS = ['clouds', 'cloud', 'sky', 'storm', 'weather', 'rain cloud']\n",
    "\n",
    "var_names = [\"api_key\", \"reqId\", \"api_url\", \"extras\"]\n",
    "re_expressions = [r\"(api_key)=([\\dabcdef]*)(&)\", r\"(reqId)=([\\dabcdef]*)(&)\", r\"(https:\\/\\/(\\w+\\.?)+(\\/\\w+)+)(\\?)\", r\"extras=((\\w+(%2)?)+?)?&\"]\n",
    "groups = [2,2,1,1]\n",
    "\n",
    "variables = [dict(zip([\"var_name\", \"regex\", 'group'], each)) for each in [each for each in zip(var_names, re_expressions, groups)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_api_call_string():\n",
    "    ''' use selenium to get the api_call string'''\n",
    "    \n",
    "    options = Options()\n",
    "\n",
    "    if HEADLESS: options.add_argument('--headless')\n",
    "\n",
    "    caps = DesiredCapabilities.CHROME\n",
    "    caps['loggingPref'] = {'performance': 'ALL'}\n",
    "\n",
    "    driver = webdriver.Chrome(options = options, desired_capabilities=caps)\n",
    "\n",
    "    xhrCallIntercept_js = \"\"\"\n",
    "    (function(XHR) {\n",
    "      \"use strict\";\n",
    "\n",
    "      var element = document.createElement('div');\n",
    "      element.id = \"interceptedResponse\";\n",
    "      element.appendChild(document.createTextNode(\"\"));\n",
    "      document.body.appendChild(element);\n",
    "\n",
    "      var open = XHR.prototype.open;\n",
    "      var send = XHR.prototype.send;\n",
    "\n",
    "      XHR.prototype.open = function(method, url, async, user, pass) {\n",
    "        this._url = url; // want to track the url requested\n",
    "        open.call(this, method, url, async, user, pass);\n",
    "      };\n",
    "\n",
    "      XHR.prototype.send = function(data) {\n",
    "        var self = this;\n",
    "        var oldOnReadyStateChange;\n",
    "        var url = this._url;\n",
    "\n",
    "        function onReadyStateChange() {\n",
    "          if(self.status === 200 && self.readyState == 4 /* complete */) {\n",
    "            document.getElementById(\"interceptedResponse\").innerHTML +=\n",
    "              '{\"data\":' + self._url + ', \"headers\" :' + self.headers + ' }*****';\n",
    "          }\n",
    "          if(oldOnReadyStateChange) {\n",
    "            oldOnReadyStateChange();\n",
    "          }\n",
    "        }\n",
    "\n",
    "        if(this.addEventListener) {\n",
    "          this.addEventListener(\"readystatechange\", onReadyStateChange,\n",
    "            false);\n",
    "        } else {\n",
    "          oldOnReadyStateChange = this.onreadystatechange;\n",
    "          this.onreadystatechange = onReadyStateChange;\n",
    "        }\n",
    "        send.call(this, data);\n",
    "      }\n",
    "    })(XMLHttpRequest);\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        url = FLICKR + \"?has_geo=1&media=photos&view_all=1&text=\" + TAGS[0]\n",
    "\n",
    "        driver.get(url)\n",
    "\n",
    "        driver.execute_script(xhrCallIntercept_js)\n",
    "\n",
    "        if VERBOSE >=1: print('title : \"{}\"'.format(driver.title))\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error! Cannot open search page: ' + str(e))\n",
    "\n",
    "    wait = False\n",
    "    while wait != True:\n",
    "        if VERBOSE >= 1: print(\"Getting AJAX data...\")\n",
    "        # trying scroll to trigger and api call\n",
    "        try:\n",
    "            if VERBOSE >= 3: print('attempting Scroll!')\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            if VERBOSE >= 3: print('Scrolled...')\n",
    "\n",
    "            # waiting for the api call to be included in the DOM\n",
    "            wait = WebDriverWait(driver, 15).until(EC.text_to_be_present_in_element((By.ID, \"interceptedResponse\"), \"api_key\"))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"intercept failed!:\" + str(e))\n",
    "\n",
    "        intercepts = driver.find_elements_by_id('interceptedResponse')\n",
    "\n",
    "    if wait == True and VERBOSE >= 1: print('ajax call intercepted!\\n')\n",
    "    xhr_api_call = intercepts[0].text\n",
    "\n",
    "    cookies = driver.get_cookies()\n",
    "    driver.close()\n",
    "    \n",
    "    return xhr_api_call, cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def parse_api_call(call_string):\n",
    "    ''' parsing data from DOM element '''\n",
    "    #creating variables for each parsed data\n",
    "    for each in variables:\n",
    "\n",
    "        if  re.search(each[\"regex\"], string=call_string, flags=re.MULTILINE) != None:\n",
    "            globals()[each[\"var_name\"]] = re.search(each[\"regex\"], string=call_string, flags=re.MULTILINE).group(each[\"group\"])\n",
    "        else:\n",
    "            globals()[each[\"var_name\"]] = None\n",
    "\n",
    "    if VERBOSE >= 2:\n",
    "        print(\"Extracted ajax params:--------\\n\")\n",
    "        for each in var_names:\n",
    "            print(\"%(var)s :     %(value)s\" % {\"var\": each.ljust(10, ' '), \"value\" : globals()[each]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_date_ranges(path, params, session, start, stop, offset):\n",
    "    \n",
    "    '''From one big range construct a bunch of contiguous ones joined\n",
    "    end to end containing aproximately 4000 photos each'''\n",
    "\n",
    "    # copying request parameters to prepare to simultaneous execusion\n",
    "    params_lcl = deepcopy(params)\n",
    "\n",
    "    # initializing time index\n",
    "    params_lcl['min_upload_date'] = stop\n",
    "    \n",
    "    ranges = ''\n",
    "\n",
    "    while params_lcl['min_upload_date'].timestamp() >= start.timestamp():\n",
    "        if VERBOSE >= 3: print(\"\".ljust(20, '+'))\n",
    "\n",
    "        params_lcl['max_upload_date'] = params_lcl['min_upload_date']\n",
    "        params_lcl['min_upload_date'] -= datetime.timedelta(days=offset)\n",
    "\n",
    "        total_photos = s.get(api_url, params=params_lcl).json()['photos']['total']\n",
    "        if VERBOSE >=3: print(f\"New date range: {params_lcl['min_upload_date']} to \\\n",
    "        {params_lcl['max_upload_date']}______ total photos: {total_photos}\")\n",
    "\n",
    "        params_lcl['min_upload_date'], next_batch_size, offset = find_best_date_range(session=s\n",
    "                                               ,params=params_lcl\n",
    "                                               , start=params_lcl['min_upload_date']\n",
    "                                               , stop=params_lcl['max_upload_date']\n",
    "                                               , total_photos=total_photos\n",
    "                                               , offset=offset)\n",
    "\n",
    "        if VERBOSE >= 2: print(f\"Next suitable range!: {params_lcl['min_upload_date']} to \\\n",
    "        {params_lcl['max_upload_date']}______ total photos : {next_batch_size}\".ljust(120, ' '))\n",
    "        \n",
    "        ranges += f\"\\n{term},{params_lcl['min_upload_date']},{params_lcl['max_upload_date']},{next_batch_size}\"\n",
    "    print(ranges)    \n",
    "    try:\n",
    "        with open(ranges_file, 'a') as outfile:\n",
    "            outfile.write(ranges)\n",
    "        if VERBOSE >= 3: print(f\"{ranges_file} written succesfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"problem dumping json data: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def looping_over_date_range(path, params, session, start, stop, offset):\n",
    "    ''' loops over given date range'''\n",
    "\n",
    "    # copying request parameters to prepare to simultaneous execusion\n",
    "    params_lcl = deepcopy(params)\n",
    "\n",
    "    last_response_time = 0\n",
    "\n",
    "    # initializing time index\n",
    "    params_lcl['min_upload_date'] = stop\n",
    "\n",
    "    while params_lcl['min_upload_date'].timestamp() >= start.timestamp():\n",
    "        if VERBOSE >= 3: print(\"\".ljust(20, '+'))\n",
    "\n",
    "        params_lcl['max_upload_date'] = params_lcl['min_upload_date']\n",
    "        params_lcl['min_upload_date'] -= datetime.timedelta(days=offset)\n",
    "\n",
    "        total_photos = s.get(api_url, params=params_lcl).json()['photos']['total']\n",
    "        if VERBOSE >=3: print(f\"New date range: {params_lcl['min_upload_date']} to {params_lcl['max_upload_date']}______ total photos: {total_photos}\")\n",
    "\n",
    "        params_lcl['min_upload_date'], next_batch_size, offset = find_best_date_range(session=s\n",
    "                                               ,params=params_lcl\n",
    "                                               , start=params_lcl['min_upload_date']\n",
    "                                               , stop=params_lcl['max_upload_date']\n",
    "                                               , total_photos=total_photos\n",
    "                                               , offset=offset)\n",
    "\n",
    "        if VERBOSE >= 2: print(f\"Next suitable range: {params_lcl['min_upload_date']} to {params_lcl['max_upload_date']}______ total photos : {next_batch_size}\".ljust(120, ' '))\n",
    "\n",
    "        if VERBOSE >= 1: print(f'starting JSON dump...')\n",
    "\n",
    "        if TEST and VERBOSE > 3:\n",
    "            print(\" fake writing to file \")\n",
    "        else:\n",
    "            write_each_page_as_json_file(path=DATA_PATH, call_params=params_lcl, session=s)\n",
    "\n",
    "        time.sleep(0.2)\n",
    "        time.sleep(last_response_time * random.uniform(COURTESY_SLEEP[0], COURTESY_SLEEP[1]) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def find_best_date_range(session, params, start, stop, total_photos, offset):\n",
    "\n",
    "    call_params = deepcopy(params)\n",
    "    # creating local variables to avoid multiprocessing issues down the line\n",
    "    call_params['per_page'] = 1\n",
    "    call_params['extras'] = ''\n",
    "\n",
    "    if VERBOSE >=3: print(f\"Finding a better range (in 20 attempts or less) ...\")\n",
    "    repeats = 0\n",
    "\n",
    "    # This loop check whether the returned total photos are just a hair under\n",
    "    # which is the maximum allowed by the api. If not it cleverly adjusts the\n",
    "    # offset. The adjustment value used is difference ratio to the wanted\n",
    "    # number of photos (the assumption for this heuristic is that for a small\n",
    "    # range the uploaded photos density will not change much. And thus the\n",
    "    # difference % when applied to the range will give us a ballpark of the wanted range)\n",
    "\n",
    "    while (int(total_photos) > 4000 or int(total_photos) < 3990) and not (int(total_photos) < 4000 and repeats > 20):\n",
    "\n",
    "        if int(total_photos) > 4000:\n",
    "            if VERBOSE >=3: print(f\"({str(repeats)}): too many    ({total_photos.ljust(5, '+')})\", end = '\\r')\n",
    "            # here the % will be small because we overshot the value wanted\n",
    "            offset = offset * 4000/ int(total_photos)\n",
    "\n",
    "        if int(total_photos) <= 4000:\n",
    "\n",
    "            if VERBOSE >=3: print(f\"({str(repeats)}): not enough  ({total_photos.ljust(5, '-')})\", end = '\\r')\n",
    "            # here the % will be big because we underestimated the range (plus a small nudge)\n",
    "            offset = offset * 4000 / int(total_photos)\n",
    "\n",
    "        start = stop - datetime.timedelta(offset)\n",
    "\n",
    "        # shifting the date range\n",
    "        call_params['min_upload_date'] = start\n",
    "        total_photos = session.get(api_url, params=call_params).json()['photos']['total']\n",
    "\n",
    "        repeats += 1\n",
    "        # if VERBOSE >3 and TEST: time.sleep(1)\n",
    "    return start, total_photos, offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def write_each_page_as_json_file(path, call_params, session):\n",
    "\n",
    "    for each in added_params: call_params[each] = added_params[each]\n",
    "\n",
    "    # making_sure the request pages are correct\n",
    "    call_params['per_page'] = PHOTOS_PER_PAGE\n",
    "    pages = s.get(api_url, params=call_params).json()['photos']['pages']\n",
    "\n",
    "    for page in range(1, 1 + pages):\n",
    "        print(f\"Requesting page {page}...\".ljust(120, ' '),  end='\\r')\n",
    "\n",
    "        call_params['page'] = page\n",
    "\n",
    "        before = dt.now().timestamp()\n",
    "\n",
    "        try:\n",
    "            response = session.get(api_url, params=call_params)\n",
    "        except Exception as e:\n",
    "            print(f\"Couldn't request JSON data:____ {e}\")\n",
    "        after = dt.now().timestamp()\n",
    "\n",
    "        last_response_time = after - before\n",
    "\n",
    "        # Trying to write JSON data to file\n",
    "        file_to_be_written = f\"{path}{term}_{str(call_params['min_upload_date'].timestamp())}-{str(call_params['max_upload_date'].timestamp())}_{page}.json\"\n",
    "        #if VERBOSE >=3: print(f\" file path to be written: {file_to_be_written}\\n\\n\")\n",
    "        try:\n",
    "            with open(file_to_be_written, 'w') as outfile:\n",
    "                json.dump(response.json(), outfile)\n",
    "\n",
    "            time_it_took = str(round(last_response_time, 2))\n",
    "            print(f\"{file_to_be_written} written succesfully! took {time_it_took} s\")\n",
    "            time.sleep(0.2)\n",
    "        except Exception as e:\n",
    "            print(f\"problem dumping json data: {str(e)}\")\n",
    "        if VERBOSE >=2: print(f'sleeping for {last_response_time * random.uniform(COURTESY_SLEEP[0], COURTESY_SLEEP[1])} seconds... (for courtesy :P )'.ljust(120, ' '), end = '\\r')\n",
    "        time.sleep(last_response_time * random.uniform(COURTESY_SLEEP[0], COURTESY_SLEEP[1]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : \"Search: clouds | Flickr\"\n",
      "Getting AJAX data...\n",
      "attempting Scroll!\n",
      "Scrolled...\n",
      "ajax call intercepted!\n",
      "\n",
      "Extracted ajax params:--------\n",
      "\n",
      "api_key    :     fc3f615bbb8ca8e17f26b216ba1212c3\n",
      "reqId      :     6d2058b5\n",
      "api_url    :     https://api.flickr.com/services/rest\n",
      "extras     :     can_comment%2Ccount_comments%2Ccount_faves%2Cdescription%2Cisfavorite%2Clicense%2Cmedia%2Cneeds_interstitial%2Cowner_name%2Cpath_alias%2Crealname%2Crotation%2Curl_sq%2Curl_q%2Curl_t%2Curl_s%2Curl_n%2Curl_w%2Curl_m%2Curl_z%2Curl_c%2Curl_l\n",
      "++++++++++++++++++++\n",
      "New date range: 2019-12-25 23:13:46.384834 to         2019-12-28 23:13:46.384834______ total photos: 827\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-12-15 08:50:05.875628 to         2019-12-28 23:13:46.384834______ total photos : 3991        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-12-01 18:26:25.366422 to         2019-12-15 08:50:05.875628______ total photos: 3858\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-12-01 14:06:57.983259 to         2019-12-15 08:50:05.875628______ total photos : 3994        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-11-17 19:23:50.090890 to         2019-12-01 14:06:57.983259______ total photos: 4923\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-11-19 20:08:04.598769 to         2019-12-01 14:06:57.983259______ total photos : 3889        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-11-08 02:09:11.214279 to         2019-11-19 20:08:04.598769______ total photos: 4031\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-11-08 04:48:37.737462 to         2019-11-19 20:08:04.598769______ total photos : 4000        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-10-27 13:29:10.876155 to         2019-11-08 04:48:37.737462______ total photos: 4689\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-10-29 06:05:47.786513 to         2019-11-08 04:48:37.737462______ total photos : 3978        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-10-19 07:22:57.835564 to         2019-10-29 06:05:47.786513______ total photos: 3861\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-10-18 20:51:38.280531 to         2019-10-29 06:05:47.786513______ total photos : 3992        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-10-08 11:37:28.774549 to         2019-10-18 20:51:38.280531______ total photos: 4199\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-10-08 21:35:11.735494 to         2019-10-18 20:51:38.280531______ total photos : 3993        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-09-28 22:18:45.190457 to         2019-10-08 21:35:11.735494______ total photos: 4344\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-09-29 14:45:13.136352 to         2019-10-08 21:35:11.735494______ total photos : 3997        \n",
      "\n",
      "clouds,2019-12-15 08:50:05.875628,2019-12-28 23:13:46.384834,3991\n",
      "clouds,2019-12-01 14:06:57.983259,2019-12-15 08:50:05.875628,3994\n",
      "clouds,2019-11-19 20:08:04.598769,2019-12-01 14:06:57.983259,3889\n",
      "clouds,2019-11-08 04:48:37.737462,2019-11-19 20:08:04.598769,4000\n",
      "clouds,2019-10-29 06:05:47.786513,2019-11-08 04:48:37.737462,3978\n",
      "clouds,2019-10-18 20:51:38.280531,2019-10-29 06:05:47.786513,3992\n",
      "clouds,2019-10-08 21:35:11.735494,2019-10-18 20:51:38.280531,3993\n",
      "clouds,2019-09-29 14:45:13.136352,2019-10-08 21:35:11.735494,3997\n",
      "./date_ranges_2019-10-08 19:57:38_2019-12-28.csv written succesfully!\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Finished for term: clouds   in date range : from 2019-10-08 19:57:38 to 2019-12-28 23:13:46.384834\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "++++++++++++++++++++\n",
      "New date range: 2019-12-25 23:13:46.384834 to         2019-12-28 23:13:46.384834______ total photos: 827\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-12-15 08:50:05.875628 to         2019-12-28 23:13:46.384834______ total photos : 3991        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-12-01 18:26:25.366422 to         2019-12-15 08:50:05.875628______ total photos: 3858\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-12-01 14:06:57.983259 to         2019-12-15 08:50:05.875628______ total photos : 3994        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-11-17 19:23:50.090890 to         2019-12-01 14:06:57.983259______ total photos: 4923\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-11-19 20:08:04.598769 to         2019-12-01 14:06:57.983259______ total photos : 3889        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-11-08 02:09:11.214279 to         2019-11-19 20:08:04.598769______ total photos: 4031\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-11-08 04:48:37.737462 to         2019-11-19 20:08:04.598769______ total photos : 4000        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-10-27 13:29:10.876155 to         2019-11-08 04:48:37.737462______ total photos: 4689\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-10-29 06:05:47.786513 to         2019-11-08 04:48:37.737462______ total photos : 3978        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-10-19 07:22:57.835564 to         2019-10-29 06:05:47.786513______ total photos: 3861\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-10-18 20:51:38.280531 to         2019-10-29 06:05:47.786513______ total photos : 3992        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-10-08 11:37:28.774549 to         2019-10-18 20:51:38.280531______ total photos: 4199\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-10-08 21:35:11.735494 to         2019-10-18 20:51:38.280531______ total photos : 3993        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-09-28 22:18:45.190457 to         2019-10-08 21:35:11.735494______ total photos: 4344\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-09-29 14:45:13.136352 to         2019-10-08 21:35:11.735494______ total photos : 3997        \n",
      "\n",
      "cloud,2019-12-15 08:50:05.875628,2019-12-28 23:13:46.384834,3991\n",
      "cloud,2019-12-01 14:06:57.983259,2019-12-15 08:50:05.875628,3994\n",
      "cloud,2019-11-19 20:08:04.598769,2019-12-01 14:06:57.983259,3889\n",
      "cloud,2019-11-08 04:48:37.737462,2019-11-19 20:08:04.598769,4000\n",
      "cloud,2019-10-29 06:05:47.786513,2019-11-08 04:48:37.737462,3978\n",
      "cloud,2019-10-18 20:51:38.280531,2019-10-29 06:05:47.786513,3992\n",
      "cloud,2019-10-08 21:35:11.735494,2019-10-18 20:51:38.280531,3993\n",
      "cloud,2019-09-29 14:45:13.136352,2019-10-08 21:35:11.735494,3997\n",
      "./date_ranges_2019-10-08 19:57:38_2019-12-28.csv written succesfully!\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Finished for term: cloud   in date range : from 2019-10-08 19:57:38 to 2019-12-28 23:13:46.384834\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "++++++++++++++++++++\n",
      "New date range: 2019-12-25 23:13:46.384834 to         2019-12-28 23:13:46.384834______ total photos: 1313\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-12-18 10:05:14.199486 to         2019-12-28 23:13:46.384834______ total photos : 3997        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-12-07 20:56:42.014138 to         2019-12-18 10:05:14.199486______ total photos: 3913\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-12-07 15:19:00.281420 to         2019-12-18 10:05:14.199486______ total photos : 4000        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-11-26 20:32:46.363354 to         2019-12-07 15:19:00.281420______ total photos: 4108\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-11-27 04:02:25.232249 to         2019-12-07 15:19:00.281420______ total photos : 4000        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-11-16 16:45:50.183078 to         2019-11-27 04:02:25.232249______ total photos: 4923\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-11-18 11:06:12.495152 to         2019-11-27 04:02:25.232249______ total photos : 4000        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-11-09 18:09:59.758055 to         2019-11-18 11:06:12.495152______ total photos: 4148\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-11-10 04:35:59.002784 to         2019-11-18 11:06:12.495152______ total photos : 3998        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-11-01 22:05:45.510416 to         2019-11-10 04:35:59.002784______ total photos: 3873\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-11-01 12:40:24.775220 to         2019-11-10 04:35:59.002784______ total photos : 3998        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-10-23 20:44:50.547656 to         2019-11-01 12:40:24.775220______ total photos: 4284\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-10-24 12:18:38.943830 to         2019-11-01 12:40:24.775220______ total photos : 3990        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-10-16 11:56:53.112440 to         2019-10-24 12:18:38.943830______ total photos: 3957\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-10-16 09:51:27.777400 to         2019-10-24 12:18:38.943830______ total photos : 3996        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-10-08 07:24:16.610970 to         2019-10-16 09:51:27.777400______ total photos: 4094\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-10-08 10:51:59.896117 to         2019-10-16 09:51:27.777400______ total photos : 3998        \n",
      "\n",
      "sky,2019-12-18 10:05:14.199486,2019-12-28 23:13:46.384834,3997\n",
      "sky,2019-12-07 15:19:00.281420,2019-12-18 10:05:14.199486,4000\n",
      "sky,2019-11-27 04:02:25.232249,2019-12-07 15:19:00.281420,4000\n",
      "sky,2019-11-18 11:06:12.495152,2019-11-27 04:02:25.232249,4000\n",
      "sky,2019-11-10 04:35:59.002784,2019-11-18 11:06:12.495152,3998\n",
      "sky,2019-11-01 12:40:24.775220,2019-11-10 04:35:59.002784,3998\n",
      "sky,2019-10-24 12:18:38.943830,2019-11-01 12:40:24.775220,3990\n",
      "sky,2019-10-16 09:51:27.777400,2019-10-24 12:18:38.943830,3996\n",
      "sky,2019-10-08 10:51:59.896117,2019-10-16 09:51:27.777400,3998\n",
      "./date_ranges_2019-10-08 19:57:38_2019-12-28.csv written succesfully!\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Finished for term: sky   in date range : from 2019-10-08 19:57:38 to 2019-12-28 23:13:46.384834\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "++++++++++++++++++++\n",
      "New date range: 2019-12-25 23:13:46.384834 to         2019-12-28 23:13:46.384834______ total photos: 100\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-10-23 17:09:31.433254 to         2019-12-28 23:13:46.384834______ total photos : 3958        \n",
      "++++++++++++++++++++\n",
      "New date range: 2019-08-18 11:05:16.481674 to         2019-10-23 17:09:31.433254______ total photos: 4775\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2019-08-27 09:06:05.905047 to         2019-10-23 17:09:31.433254______ total photos : 3990        \n",
      "\n",
      "storm,2019-10-23 17:09:31.433254,2019-12-28 23:13:46.384834,3958\n",
      "storm,2019-08-27 09:06:05.905047,2019-10-23 17:09:31.433254,3990\n",
      "./date_ranges_2019-10-08 19:57:38_2019-12-28.csv written succesfully!\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Finished for term: storm   in date range : from 2019-10-08 19:57:38 to 2019-12-28 23:13:46.384834\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    xhr_api_call, cookies = get_api_call_string()\n",
    "\n",
    "    parse_api_call(xhr_api_call)\n",
    "\n",
    "    extras = extras.replace('%2C', ',')\n",
    "\n",
    "    added_params = {\n",
    "        \"extras\" : '',\n",
    "        #\"extras\" : extras + ','+ ADD_EXTRAS,\n",
    "        \"per_page\" : 1,\n",
    "        \"api_key\" : api_key,\n",
    "        \"reqId\" : reqId,\n",
    "    }\n",
    "\n",
    "    for each in added_params: params[each] = added_params[each]\n",
    "\n",
    "    spoof_webdriver = False\n",
    "\n",
    "    if spoof_webdriver: ua = UserAgent()\n",
    "\n",
    "    with requests.sessions.Session() as s:\n",
    "        for cookie in cookies:\n",
    "            s.cookies.set(cookie['name'], cookie['value'])\n",
    "        if spoof_webdriver: s.headers['User-Agent'] = str(ua.chrome)\n",
    "\n",
    "    offset = 3    \n",
    "\n",
    "    TEST_RANGE = TAGS[:-2] if TEST and VERBOSE > 3 else TAGS\n",
    "    \n",
    "    date_format = '%Y-%m-%d'\n",
    "    ranges_file = f'./date_ranges_{AFTER_DATE}_{BEFORE_DATE.strftime(date_format)}.csv'\n",
    "    \n",
    "    try:\n",
    "        with open(ranges_file, 'w') as outfile:\n",
    "            outfile.write(\"Search_Term, Uploaded_After, Uploaded_Before, Batch_Size\")\n",
    "    except Exception as e:\n",
    "        print(f\"problem dumping json data: {str(e)}\")\n",
    "    \n",
    "    for term in TEST_RANGE:\n",
    "\n",
    "        params['text'] = term\n",
    "\n",
    "        first_range = True\n",
    "\n",
    "        start = AFTER_DATE\n",
    "        stop = BEFORE_DATE\n",
    "\n",
    "        params['min_upload_date'] = start\n",
    "        params['max_upload_date'] = stop\n",
    "        \n",
    "        construct_date_ranges(path=DATA_PATH, params=params, session=s, start=params['min_upload_date'], stop=params['max_upload_date'], offset = offset)\n",
    "\n",
    "        #looping_over_date_range(path=DATA_PATH, params=params, session=s, start=params['min_upload_date'], stop=params['max_upload_date'], offset = 3)\n",
    "        if VERBOSE >=3:\n",
    "            print(\"\".ljust(120, \"-\"))\n",
    "            print(f\"Finished for term: {term}   in date range : from {start} to {stop}\")\n",
    "            print(\"\".ljust(120, \"-\"))\n",
    "\n",
    "        #time.sleep(random.uniform(COURTESY_SLEEP[0], COURTESY_SLEEP[1]) * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
