{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, textwrap, time, json, re, requests, random, datetime, copy\n",
    "from datetime import datetime as dt\n",
    "from copy import deepcopy\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "global driver, params, AFTER_DATE ,BEFORE_DATE ,COURTESY_SLEEP ,PHOTOS_PER_PAGE ,VERBOSE ,TEST ,DUMP_PATH ,ADD_EXTRAS, HEADLESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "AFTER_DATE = dt.fromtimestamp(1262304000)\n",
    "BEFORE_DATE = dt.now()\n",
    "PHOTOS_PER_PAGE =  250\n",
    "VERBOSE =  4\n",
    "DUMP_PATH = './'\n",
    "TEST = True\n",
    "ADD_EXTRAS = 'url_o,original_format,date_taken,date_upload,geo'\n",
    "HEADLESS = True\n",
    "COURTESY_SLEEP = \"0, 0.000000001\"\n",
    "GET_DATES_ONLY = True\n",
    "BBOX_PHOTOS_PER_PAGE = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-a AFTER_DATE] [-b BEFORE_DATE]\n",
      "                             [-s COURTESY_SLEEP] [-n PHOTOS_PER_PAGE] [-v]\n",
      "                             [-p DUMP_PATH] [-t] [-g] [-w] [-x ADD_EXTRAS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/hadakechi/Library/Jupyter/runtime/kernel-c908b222-326c-4671-b0a6-e9500f7e6224.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hadakechi/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3327: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=textwrap.dedent('''\\\n",
    "        scrape JSONs containing photos from flickr\n",
    "         '''))\n",
    "\n",
    "parser.add_argument(\"-a\", \"--after_date\"\n",
    "                    , help=\"Start date (in unix timestamp format).\\Defaults to yesterday\"\n",
    "                    , type=float, default=dt.now().timestamp() - (30 * 24 * 3600))\n",
    "parser.add_argument(\"-b\", \"--before_date\"\n",
    "                    , help=\"End date (in unix timestamp format). Defaults to now\", type=float\n",
    "                    , default=dt.now().timestamp())\n",
    "parser.add_argument(\"-s\", \"--courtesy_sleep\"\n",
    "                    , help=\"Range (in string format) from which a random value will be chosen to sleep randomly. example: '1.3, 2.7'\", type=str, default=\"1.3, 2.7\")\n",
    "parser.add_argument(\"-n\", \"--photos_per_page\"\n",
    "                    , help=\"Photos per file. Default is 500 which is the maximum\", type=int\n",
    "                    , default=500)\n",
    "parser.add_argument(\"-v\", \"--verbose\"\n",
    "                    , help=\"increase output verbosity\", action=\"count\", default=0)\n",
    "parser.add_argument(\"-p\", \"--dump_path\"\n",
    "                    , help=\"Path where to dump json files\", type=str, default='./')\n",
    "parser.add_argument(\"-t\", \"--test\"\n",
    "                    , help=\"test mode\", action='store_true')\n",
    "parser.add_argument(\"-g\", \"--get_dates_only\"\n",
    "                    , help=\"Only scan for suitable ranges and store them on csv file.\\\n",
    "                    \\n suitable ranges are dates where the photos returned aproximates\\\n",
    "                    4000\", action='store_true')\n",
    "parser.add_argument(\"-w\", \"--webdriver\"\n",
    "                    , help=\"Turn off headless mode for on the chrome webdriver\"\n",
    "                    , action='store_false')\n",
    "parser.add_argument(\"-x\", \"--add_extras\"\n",
    "                    , help=\"extra json fields to request. Defaults to 'url_o,original_format\\\n",
    "                    ,date_taken,date_upload,geo'\", type=str\n",
    "                    , default=\"url_o,original_format,date_taken,date_upload,geo\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "args.__dict__['HEADLESS'] = args.webdriver\n",
    "\n",
    "# ansigning global variables from cmdline args for easy typing\n",
    "for each in args.__dict__: globals()[each.upper()] = args.__dict__[each]\n",
    "\n",
    "# making sure the dates are in datetime format\n",
    "for each in [\"AFTER_DATE\", \"BEFORE_DATE\"]:\n",
    "    if type(each) != type(dt.now()):\n",
    "        try:\n",
    "            globals()[each] = dt.fromtimestamp(globals()[each])\n",
    "        except Exception as e:\n",
    "            print(f\"please make sure the dates entered are in unix timestamps format: {e}\")\n",
    "\n",
    "# printing parameters for easy debugging\n",
    "if VERBOSE >=3:\n",
    "    print(\"\".ljust(120, \"_\") + \"\\nscript parameters\")\n",
    "    for each in args.__dict__:\n",
    "        print(f\"{each.upper()}: {args.__dict__[each]}\")\n",
    "    print(\"\".ljust(120, \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "COURTESY_SLEEP = [float(COURTESY_SLEEP.split(',')[0]) , float(COURTESY_SLEEP.split(',')[1])]\n",
    "if TEST and VERBOSE > 3: COURTESY_SLEEP = [0, 0.000000001]\n",
    "\n",
    "\n",
    "DATA_PATH = ('./test/' if TEST else DUMP_PATH)\n",
    "\n",
    "params = {\n",
    "    #\n",
    "    \"bbox\" : '-124.799423, 24.750821, -54.517891, 54.306268', \n",
    "    \"sort\" : \"relevance\",\n",
    "    \"parse_tags\" : \"1\",\n",
    "    \"content_type\" : \"7\",\n",
    "    \"lang\": \"en-US\",\n",
    "    \"has_geo\" :\"1\",\n",
    "    \"media\" : \"photos\",\n",
    "    \"view_all\" : \"1\",\n",
    "    \"text\" : \"clouds\",\n",
    "    \"viewerNSID\": \"\",\n",
    "    \"method\" : \"flickr.photos.search\",\n",
    "    \"csrf\" : \"\",\n",
    "    \"format\" : \"json\",\n",
    "    \"hermes\" : \"1\",\n",
    "    \"hermesClient\" : \"1\",\n",
    "    \"nojsoncallback\" : \"1\",\n",
    "    \"geo_context\": '2', # 0: all , 1: indoors, 2 : outdoors\n",
    "    \"privacy_filter\" : 1\n",
    "}\n",
    "\n",
    "privacy_filters = '''\n",
    "\"public photos\" : '1',\n",
    "\"private photos visible to friends\" : '2',\n",
    "\"private photos visible to family\" : '3',\n",
    "\"private photos visible to friends & family\": '4',\n",
    "\"completely private photos\" : '5'\n",
    "'''\n",
    "\n",
    "FLICKR = 'https://flickr.com/search/'\n",
    "TAGS = ['rain cloud', 'sun clouds', 'sunny clouds', 'clouds', 'cloud', 'sky', 'storm', 'weather', 'cloudy']\n",
    "\n",
    "var_names = [\"api_key\", \"reqId\", \"api_url\", \"extras\"]\n",
    "re_expressions = [r\"(api_key)=([\\dabcdef]*)(&)\", r\"(reqId)=([\\dabcdef]*)(&)\", r\"(https:\\/\\/(\\w+\\.?)+(\\/\\w+)+)(\\?)\", r\"extras=((\\w+(%2)?)+?)?&\"]\n",
    "groups = [2,2,1,1]\n",
    "\n",
    "variables = [dict(zip([\"var_name\", \"regex\", 'group'], each)) for each in [each for each in zip(var_names, re_expressions, groups)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_call_string():\n",
    "    ''' use selenium to get the api_call string'''\n",
    "    \n",
    "    options = Options()\n",
    "\n",
    "    if HEADLESS: options.add_argument('--headless')\n",
    "\n",
    "    caps = DesiredCapabilities.CHROME\n",
    "    caps['loggingPref'] = {'performance': 'ALL'}\n",
    "\n",
    "    driver = webdriver.Chrome(options = options, desired_capabilities=caps)\n",
    "\n",
    "    xhrCallIntercept_js = \"\"\"\n",
    "    (function(XHR) {\n",
    "      \"use strict\";\n",
    "\n",
    "      var element = document.createElement('div');\n",
    "      element.id = \"interceptedResponse\";\n",
    "      element.appendChild(document.createTextNode(\"\"));\n",
    "      document.body.appendChild(element);\n",
    "\n",
    "      var open = XHR.prototype.open;\n",
    "      var send = XHR.prototype.send;\n",
    "\n",
    "      XHR.prototype.open = function(method, url, async, user, pass) {\n",
    "        this._url = url; // want to track the url requested\n",
    "        open.call(this, method, url, async, user, pass);\n",
    "      };\n",
    "\n",
    "      XHR.prototype.send = function(data) {\n",
    "        var self = this;\n",
    "        var oldOnReadyStateChange;\n",
    "        var url = this._url;\n",
    "\n",
    "        function onReadyStateChange() {\n",
    "          if(self.status === 200 && self.readyState == 4 /* complete */) {\n",
    "            document.getElementById(\"interceptedResponse\").innerHTML +=\n",
    "              '{\"data\":' + self._url + ', \"headers\" :' + self.headers + ' }*****';\n",
    "          }\n",
    "          if(oldOnReadyStateChange) {\n",
    "            oldOnReadyStateChange();\n",
    "          }\n",
    "        }\n",
    "\n",
    "        if(this.addEventListener) {\n",
    "          this.addEventListener(\"readystatechange\", onReadyStateChange,\n",
    "            false);\n",
    "        } else {\n",
    "          oldOnReadyStateChange = this.onreadystatechange;\n",
    "          this.onreadystatechange = onReadyStateChange;\n",
    "        }\n",
    "        send.call(this, data);\n",
    "      }\n",
    "    })(XMLHttpRequest);\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        url = FLICKR + \"?has_geo=1&media=photos&view_all=1&text=\" + TAGS[0]\n",
    "\n",
    "        driver.get(url)\n",
    "\n",
    "        driver.execute_script(xhrCallIntercept_js)\n",
    "\n",
    "        if VERBOSE >=1: print('title : \"{}\"'.format(driver.title))\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error! Cannot open search page: ' + str(e))\n",
    "\n",
    "    wait = False\n",
    "    while wait != True:\n",
    "        if VERBOSE >= 1: print(\"Getting AJAX data...\")\n",
    "        # trying scroll to trigger and api call\n",
    "        try:\n",
    "            if VERBOSE >= 3: print('attempting Scroll!')\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            if VERBOSE >= 3: print('Scrolled...')\n",
    "\n",
    "            # waiting for the api call to be included in the DOM\n",
    "            wait = WebDriverWait(driver, 15).until(EC.text_to_be_present_in_element((By.ID, \"interceptedResponse\"), \"api_key\"))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"intercept failed!:\" + str(e))\n",
    "\n",
    "        intercepts = driver.find_elements_by_id('interceptedResponse')\n",
    "\n",
    "    if wait == True and VERBOSE >= 1: print('ajax call intercepted!\\n')\n",
    "    xhr_api_call = intercepts[0].text\n",
    "\n",
    "    cookies = driver.get_cookies()\n",
    "    driver.close()\n",
    "    \n",
    "    return xhr_api_call, cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_api_call(call_string):\n",
    "    ''' parsing data from DOM element '''\n",
    "    #creating variables for each parsed data\n",
    "    for each in variables:\n",
    "\n",
    "        if  re.search(each[\"regex\"], string=call_string, flags=re.MULTILINE) != None:\n",
    "            globals()[each[\"var_name\"]] = re.search(each[\"regex\"], string=call_string, flags=re.MULTILINE).group(each[\"group\"])\n",
    "        else:\n",
    "            globals()[each[\"var_name\"]] = None\n",
    "\n",
    "    if VERBOSE >= 2:\n",
    "        print(\"Extracted ajax params:--------\\n\")\n",
    "        for each in var_names:\n",
    "            print(\"%(var)s :     %(value)s\" % {\"var\": each.ljust(10, ' '), \"value\" : globals()[each]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_date_ranges(path, params, session, start, stop, offset):\n",
    "    \n",
    "    '''From one big range construct a bunch of contiguous ones joined\n",
    "    end to end containing aproximately 4000 photos each'''\n",
    "\n",
    "    # copying request parameters to prepare to simultaneous execusion\n",
    "    params_lcl = deepcopy(params)\n",
    "\n",
    "    # initializing time index\n",
    "    params_lcl['min_upload_date'] = stop\n",
    "    \n",
    "    ranges = ''\n",
    "\n",
    "    while params_lcl['min_upload_date'].timestamp() >= start.timestamp():\n",
    "        if VERBOSE >= 3: print(\"\".ljust(20, '+'))\n",
    "\n",
    "        params_lcl['max_upload_date'] = params_lcl['min_upload_date']\n",
    "        params_lcl['min_upload_date'] -= datetime.timedelta(days=offset)\n",
    "\n",
    "        total_photos = s.get(api_url, params=params_lcl).json()['photos']['total']\n",
    "        if VERBOSE >=3: print(f\"New date range: {params_lcl['min_upload_date']} to \\\n",
    "        {params_lcl['max_upload_date']}______ total photos: {total_photos}\")\n",
    "\n",
    "        params_lcl['min_upload_date'], next_batch_size, offset = find_best_date_range(session=s\n",
    "                                               ,params=params_lcl\n",
    "                                               , start=params_lcl['min_upload_date']\n",
    "                                               , stop=params_lcl['max_upload_date']\n",
    "                                               , total_photos=total_photos\n",
    "                                               , offset=offset)\n",
    "\n",
    "        if VERBOSE >= 2: print(f\"Next suitable range!: {params_lcl['min_upload_date']} to \\\n",
    "        {params_lcl['max_upload_date']}______ total photos : {next_batch_size}\".ljust(120, ' '))\n",
    "        \n",
    "        ranges += f\"\\n{term.replace(' ','_')},{params_lcl['min_upload_date']},{params_lcl['max_upload_date']},{next_batch_size}\"\n",
    "    \n",
    "    try:\n",
    "        with open(ranges_file, 'a') as outfile:\n",
    "            outfile.write(ranges)\n",
    "        if VERBOSE >= 3: print(f\"{ranges_file} written succesfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"problem dumping json data: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def looping_over_date_range(path, params, session, start, stop, offset):\n",
    "    ''' loops over given date range'''\n",
    "\n",
    "    # copying request parameters to prepare to simultaneous execusion\n",
    "    params_lcl = deepcopy(params)\n",
    "\n",
    "    last_response_time = 0\n",
    "\n",
    "    # initializing time index\n",
    "    params_lcl['min_upload_date'] = stop\n",
    "\n",
    "    while params_lcl['min_upload_date'].timestamp() >= start.timestamp():\n",
    "        if VERBOSE >= 3: print(\"\".ljust(20, '+'))\n",
    "\n",
    "        params_lcl['max_upload_date'] = params_lcl['min_upload_date']\n",
    "        params_lcl['min_upload_date'] -= datetime.timedelta(days=offset)\n",
    "\n",
    "        total_photos = s.get(api_url, params=params_lcl).json()['photos']['total']\n",
    "        if VERBOSE >=3: print(f\"New date range: {params_lcl['min_upload_date']} to {params_lcl['max_upload_date']}______ total photos: {total_photos}\")\n",
    "\n",
    "        params_lcl['min_upload_date'], next_batch_size, offset = find_best_date_range(session=s\n",
    "                                               ,params=params_lcl\n",
    "                                               , start=params_lcl['min_upload_date']\n",
    "                                               , stop=params_lcl['max_upload_date']\n",
    "                                               , total_photos=total_photos\n",
    "                                               , offset=offset)\n",
    "\n",
    "        if VERBOSE >= 2: print(f\"Next suitable range: {params_lcl['min_upload_date']} to {params_lcl['max_upload_date']}______ total photos : {next_batch_size}\".ljust(120, ' '))\n",
    "\n",
    "        if VERBOSE >= 1: print(f'starting JSON dump...')\n",
    "\n",
    "        if TEST and VERBOSE > 3:\n",
    "            print(\" fake writing to file \")\n",
    "        else:\n",
    "            write_each_page_as_json_file(path=DATA_PATH, call_params=params_lcl, session=s)\n",
    "\n",
    "        time.sleep(0.2)\n",
    "        time.sleep(last_response_time * random.uniform(COURTESY_SLEEP[0], COURTESY_SLEEP[1]) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_date_range(session, params, start, stop, total_photos, offset):\n",
    "\n",
    "    call_params = deepcopy(params)\n",
    "    # creating local variables to avoid multiprocessing issues down the line\n",
    "    call_params['per_page'] = 1\n",
    "    call_params['extras'] = ''\n",
    "\n",
    "    if VERBOSE >=3: print(f\"Finding a better range (in 20 attempts or less) ...\")\n",
    "    repeats = 0\n",
    "\n",
    "    # This loop check whether the returned total photos are just a hair under\n",
    "    # which is the maximum allowed by the api. If not it cleverly adjusts the\n",
    "    # offset. The adjustment value used is difference ratio to the wanted\n",
    "    # number of photos (the assumption for this heuristic is that for a small\n",
    "    # range the uploaded photos density will not change much. And thus the\n",
    "    # difference % when applied to the range will give us a ballpark of the wanted range)\n",
    "\n",
    "    while (\n",
    "        int(total_photos) != 4000\n",
    "        and (\n",
    "            int(total_photos) > 4000\n",
    "            or int(total_photos) < ( 4000 * 0.99 )\n",
    "        )\n",
    "        and not (\n",
    "            int(total_photos) < 4000\n",
    "            and repeats > 20\n",
    "        )\n",
    "    ):\n",
    "\n",
    "        if int(total_photos) > 4000:\n",
    "            if VERBOSE >=3: print(f\"({str(repeats)}): too many    ({total_photos.ljust(5, '+')})\\\n",
    "            {start} --- {stop}\", end = '\\r')\n",
    "            # here the % will be small because we overshot the value wanted\n",
    "            offset = offset * 4000/ int(total_photos)\n",
    "\n",
    "        if int(total_photos) <= 4000:\n",
    "\n",
    "            if VERBOSE >=3: print(f\"({str(repeats)}): not enough  ({total_photos.ljust(5, '-')})\\\n",
    "            {start} --- {stop}\", end = '\\r')\n",
    "            # here the % will be big because we underestimated the range (plus a small nudge)\n",
    "            offset = offset * 4000 / int(total_photos)\n",
    "\n",
    "        start = stop - datetime.timedelta(offset)\n",
    "\n",
    "        # shifting the date range\n",
    "        call_params['min_upload_date'] = start\n",
    "        total_photos = session.get(api_url, params=call_params).json()['photos']['total']\n",
    "\n",
    "        repeats += 1\n",
    "        # if VERBOSE >3 and TEST: time.sleep(1)\n",
    "    return start, total_photos, offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_each_page_as_json_file(path, call_params, session):\n",
    "\n",
    "    for each in added_params: call_params[each] = added_params[each]\n",
    "\n",
    "    # making_sure the request pages are correct\n",
    "    call_params['per_page'] = PHOTOS_PER_PAGE\n",
    "    pages = s.get(api_url, params=call_params).json()['photos']['pages']\n",
    "    \n",
    "    \n",
    "    for page in range(1, 1 + pages):\n",
    "        print(f\"Requesting page {page}...\".ljust(120, ' '),  end='\\r')\n",
    "\n",
    "        call_params['page'] = page\n",
    "\n",
    "\n",
    "        try:\n",
    "            before = dt.now().timestamp()\n",
    "            response = session.get(api_url, params=call_params)\n",
    "            after = dt.now().timestamp()\n",
    "            data = response.json()\n",
    "            data['api_call_params'] = call_params\n",
    "        except Exception as e:\n",
    "            print(f\"Couldn't request JSON data:____ {e}\")\n",
    "\n",
    "        last_response_time = after - before\n",
    "\n",
    "        # Trying to write JSON data to file\n",
    "        file_to_be_written = f\"{path}{term.replace(' ','_')}_{str(call_params['min_upload_date'].timestamp())}-{str(call_params['max_upload_date'].timestamp())}_{page}.json\"\n",
    "        #if VERBOSE >=3: print(f\" file path to be written: {file_to_be_written}\\n\\n\")\n",
    "        try:\n",
    "            with open(file_to_be_written, 'w') as outfile:\n",
    "                json.dump(data.json(), outfile)\n",
    "\n",
    "            time_it_took = str(round(last_response_time, 2))\n",
    "            print(f\"{file_to_be_written} written succesfully! took {time_it_took} s\")\n",
    "            time.sleep(0.2)\n",
    "        except Exception as e:\n",
    "            print(f\"problem dumping json data: {str(e)}\")\n",
    "        if VERBOSE >=2: print(f'sleeping for {last_response_time * random.uniform(COURTESY_SLEEP[0], COURTESY_SLEEP[1])} seconds... (for courtesy :P )'.ljust(120, ' '), end = '\\r')\n",
    "        time.sleep(last_response_time * random.uniform(COURTESY_SLEEP[0], COURTESY_SLEEP[1]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : \"Search: rain cloud | Flickr\"\n",
      "Getting AJAX data...\n",
      "attempting Scroll!\n",
      "Scrolled...\n",
      "ajax call intercepted!\n",
      "\n",
      "Extracted ajax params:--------\n",
      "\n",
      "api_key    :     fc3f615bbb8ca8e17f26b216ba1212c3\n",
      "reqId      :     66314f07\n",
      "api_url    :     https://api.flickr.com/services/rest\n",
      "extras     :     can_comment%2Ccount_comments%2Ccount_faves%2Cdescription%2Cisfavorite%2Clicense%2Cmedia%2Cneeds_interstitial%2Cowner_name%2Cpath_alias%2Crealname%2Crotation%2Curl_sq%2Curl_q%2Curl_t%2Curl_s%2Curl_n%2Curl_w%2Curl_m%2Curl_z%2Curl_c%2Curl_l\n",
      "++++++++++++++++++++\n",
      "New date range: 2019-12-27 00:37:50.864681 to         2019-12-30 00:37:50.864681______ total photos: 10\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2017-07-25 18:45:46.840606 to         2019-12-30 00:37:50.864681______ total photos : 3990        \n",
      "++++++++++++++++++++\n",
      "New date range: 2015-02-19 12:53:42.816531 to         2017-07-25 18:45:46.840606______ total photos: 5953\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2015-09-25 02:52:59.042456 to         2017-07-25 18:45:46.840606______ total photos : 3967        \n",
      "++++++++++++++++++++\n",
      "New date range: 2013-11-24 11:00:11.244306 to         2015-09-25 02:52:59.042456______ total photos: 5501\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2014-07-24 23:33:14.395231 to         2015-09-25 02:52:59.042456______ total photos : 3961        \n",
      "++++++++++++++++++++\n",
      "New date range: 2013-05-23 20:13:29.748006 to         2014-07-24 23:33:14.395231______ total photos: 3840\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2013-05-09 03:18:57.188154 to         2014-07-24 23:33:14.395231______ total photos : 3971        \n",
      "++++++++++++++++++++\n",
      "New date range: 2012-02-22 07:04:39.981077 to         2013-05-09 03:18:57.188154______ total photos: 4091\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2012-03-09 05:23:52.372597 to         2013-05-09 03:18:57.188154______ total photos : 4000        \n",
      "++++++++++++++++++++\n",
      "New date range: 2011-01-08 07:28:47.557040 to         2012-03-09 05:23:52.372597______ total photos: 3725\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2010-11-29 00:14:52.019382 to         2012-03-09 05:23:52.372597______ total photos : 3962        \n",
      "++++++++++++++++++++\n",
      "New date range: 2009-08-19 19:05:51.666167 to         2010-11-29 00:14:52.019382______ total photos: 4017\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2009-08-21 18:27:01.167288 to         2010-11-29 00:14:52.019382______ total photos : 3988        \n",
      "\n",
      "rain_cloud,2017-07-25 18:45:46.840606,2019-12-30 00:37:50.864681,3990\n",
      "rain_cloud,2015-09-25 02:52:59.042456,2017-07-25 18:45:46.840606,3967\n",
      "rain_cloud,2014-07-24 23:33:14.395231,2015-09-25 02:52:59.042456,3961\n",
      "rain_cloud,2013-05-09 03:18:57.188154,2014-07-24 23:33:14.395231,3971\n",
      "rain_cloud,2012-03-09 05:23:52.372597,2013-05-09 03:18:57.188154,4000\n",
      "rain_cloud,2010-11-29 00:14:52.019382,2012-03-09 05:23:52.372597,3962\n",
      "rain_cloud,2009-08-21 18:27:01.167288,2010-11-29 00:14:52.019382,3988\n",
      "./date_ranges_2009-12-31 19:00:00_2019-12-30.csv written succesfully!\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Finished for term: rain cloud   in date range : from 2009-12-31 19:00:00 to 2019-12-30 00:37:50.864681\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "++++++++++++++++++++\n",
      "New date range: 2019-12-27 00:37:50.864681 to         2019-12-30 00:37:50.864681______ total photos: 26\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2018-12-08 19:55:21.952962 to         2019-12-30 00:37:50.864681______ total photos : 3970        \n",
      "++++++++++++++++++++\n",
      "New date range: 2017-11-17 15:12:53.041243 to         2018-12-08 19:55:21.952962______ total photos: 5529\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2018-03-28 14:50:11.789788 to         2018-12-08 19:55:21.952962______ total photos : 3997        \n",
      "++++++++++++++++++++\n",
      "New date range: 2017-07-16 09:45:01.626614 to         2018-03-28 14:50:11.789788______ total photos: 3271\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2017-05-16 21:31:40.802955 to         2018-03-28 14:50:11.789788______ total photos : 3999        \n",
      "++++++++++++++++++++\n",
      "New date range: 2016-07-05 04:13:09.816122 to         2017-05-16 21:31:40.802955______ total photos: 4699\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2016-08-14 09:55:21.658955 to         2017-05-16 21:31:40.802955______ total photos : 3995        \n",
      "++++++++++++++++++++\n",
      "New date range: 2015-11-12 22:19:02.514955 to         2016-08-14 09:55:21.658955______ total photos: 5003\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2016-01-09 17:12:02.091856 to         2016-08-14 09:55:21.658955______ total photos : 3977        \n",
      "++++++++++++++++++++\n",
      "New date range: 2015-06-06 00:28:42.524757 to         2016-01-09 17:12:02.091856______ total photos: 4293\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2015-06-17 03:50:11.605075 to         2016-01-09 17:12:02.091856______ total photos : 3992        \n",
      "++++++++++++++++++++\n",
      "New date range: 2014-11-22 14:28:21.118294 to         2015-06-17 03:50:11.605075______ total photos: 4254\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2014-12-02 19:48:54.432089 to         2015-06-17 03:50:11.605075______ total photos : 3999        \n",
      "++++++++++++++++++++\n",
      "New date range: 2014-05-20 11:47:37.259103 to         2014-12-02 19:48:54.432089______ total photos: 5569\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2014-07-19 21:59:07.875764 to         2014-12-02 19:48:54.432089______ total photos : 3965        \n",
      "++++++++++++++++++++\n",
      "New date range: 2014-03-06 00:09:21.319439 to         2014-07-19 21:59:07.875764______ total photos: 3026\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2014-01-22 01:33:49.251905 to         2014-07-19 21:59:07.875764______ total photos : 3990        \n",
      "++++++++++++++++++++\n",
      "New date range: 2013-07-27 05:08:30.628046 to         2014-01-22 01:33:49.251905______ total photos: 4574\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2013-08-13 15:13:49.315118 to         2014-01-22 01:33:49.251905______ total photos : 4000        \n",
      "++++++++++++++++++++\n",
      "New date range: 2013-03-05 04:53:49.378331 to         2013-08-13 15:13:49.315118______ total photos: 4343\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2013-03-17 22:52:58.256599 to         2013-08-13 15:13:49.315118______ total photos : 3980        \n",
      "++++++++++++++++++++\n",
      "New date range: 2012-10-20 06:32:07.198080 to         2013-03-17 22:52:58.256599______ total photos: 4657\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2012-11-11 12:17:46.825053 to         2013-03-17 22:52:58.256599______ total photos : 3984        \n",
      "++++++++++++++++++++\n",
      "New date range: 2012-07-08 01:42:35.393507 to         2012-11-11 12:17:46.825053______ total photos: 4540\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2012-07-23 19:55:34.370798 to         2012-11-11 12:17:46.825053______ total photos : 3998        \n",
      "++++++++++++++++++++\n",
      "New date range: 2012-04-04 03:33:21.916543 to         2012-07-23 19:55:34.370798______ total photos: 3573\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2012-03-20 07:04:23.391376 to         2012-07-23 19:55:34.370798______ total photos : 3973        \n",
      "++++++++++++++++++++\n",
      "New date range: 2011-11-15 18:13:12.411954 to         2012-03-20 07:04:23.391376______ total photos: 5480\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2011-12-26 17:44:27.126054 to         2012-03-20 07:04:23.391376______ total photos : 3999        \n",
      "++++++++++++++++++++\n",
      "New date range: 2011-10-03 04:24:30.860732 to         2011-12-26 17:44:27.126054______ total photos: 2783\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2011-08-22 04:56:27.441667 to         2011-12-26 17:44:27.126054______ total photos : 3999        \n",
      "++++++++++++++++++++\n",
      "New date range: 2011-04-17 16:08:27.757280 to         2011-08-22 04:56:27.441667______ total photos: 3691\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2011-04-05 00:38:21.702950 to         2011-08-22 04:56:27.441667______ total photos : 3988        \n",
      "++++++++++++++++++++\n",
      "New date range: 2010-11-16 20:20:15.964233 to         2011-04-05 00:38:21.702950______ total photos: 3685\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2010-11-05 23:06:48.482360 to         2011-04-05 00:38:21.702950______ total photos : 3990        \n",
      "++++++++++++++++++++\n",
      "New date range: 2010-06-08 21:35:15.261770 to         2010-11-05 23:06:48.482360______ total photos: 4425\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2010-06-30 07:52:36.805417 to         2010-11-05 23:06:48.482360______ total photos : 3993        \n",
      "++++++++++++++++++++\n",
      "New date range: 2010-02-21 16:38:25.128474 to         2010-06-30 07:52:36.805417______ total photos: 2981\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2010-01-08 14:13:35.333980 to         2010-06-30 07:52:36.805417______ total photos : 3980        \n",
      "++++++++++++++++++++\n",
      "New date range: 2009-07-19 20:34:33.862543 to         2010-01-08 14:13:35.333980______ total photos: 3460\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "Next suitable range!: 2009-06-28 17:09:32.658817 to         2010-01-08 14:13:35.333980______ total photos : 3964        \n",
      "\n",
      "sun_clouds,2018-12-08 19:55:21.952962,2019-12-30 00:37:50.864681,3970\n",
      "sun_clouds,2018-03-28 14:50:11.789788,2018-12-08 19:55:21.952962,3997\n",
      "sun_clouds,2017-05-16 21:31:40.802955,2018-03-28 14:50:11.789788,3999\n",
      "sun_clouds,2016-08-14 09:55:21.658955,2017-05-16 21:31:40.802955,3995\n",
      "sun_clouds,2016-01-09 17:12:02.091856,2016-08-14 09:55:21.658955,3977\n",
      "sun_clouds,2015-06-17 03:50:11.605075,2016-01-09 17:12:02.091856,3992\n",
      "sun_clouds,2014-12-02 19:48:54.432089,2015-06-17 03:50:11.605075,3999\n",
      "sun_clouds,2014-07-19 21:59:07.875764,2014-12-02 19:48:54.432089,3965\n",
      "sun_clouds,2014-01-22 01:33:49.251905,2014-07-19 21:59:07.875764,3990\n",
      "sun_clouds,2013-08-13 15:13:49.315118,2014-01-22 01:33:49.251905,4000\n",
      "sun_clouds,2013-03-17 22:52:58.256599,2013-08-13 15:13:49.315118,3980\n",
      "sun_clouds,2012-11-11 12:17:46.825053,2013-03-17 22:52:58.256599,3984\n",
      "sun_clouds,2012-07-23 19:55:34.370798,2012-11-11 12:17:46.825053,3998\n",
      "sun_clouds,2012-03-20 07:04:23.391376,2012-07-23 19:55:34.370798,3973\n",
      "sun_clouds,2011-12-26 17:44:27.126054,2012-03-20 07:04:23.391376,3999\n",
      "sun_clouds,2011-08-22 04:56:27.441667,2011-12-26 17:44:27.126054,3999\n",
      "sun_clouds,2011-04-05 00:38:21.702950,2011-08-22 04:56:27.441667,3988\n",
      "sun_clouds,2010-11-05 23:06:48.482360,2011-04-05 00:38:21.702950,3990\n",
      "sun_clouds,2010-06-30 07:52:36.805417,2010-11-05 23:06:48.482360,3993\n",
      "sun_clouds,2010-01-08 14:13:35.333980,2010-06-30 07:52:36.805417,3980\n",
      "sun_clouds,2009-06-28 17:09:32.658817,2010-01-08 14:13:35.333980,3964\n",
      "./date_ranges_2009-12-31 19:00:00_2019-12-30.csv written succesfully!\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Finished for term: sun clouds   in date range : from 2009-12-31 19:00:00 to 2019-12-30 00:37:50.864681\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "++++++++++++++++++++\n",
      "New date range: 2019-12-27 00:37:50.864681 to         2019-12-30 00:37:50.864681______ total photos: 2\n",
      "Finding a better range (in 20 attempts or less) ...\n",
      "(7): not enough  (3776-)            2015-06-24 00:03:00.533809 --- 2019-12-30 00:37:50.864681\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-84184fafaa89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m                                   \u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min_upload_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                                   \u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_upload_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                                   , offset = offset)\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mlooping_over_date_ranges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min_upload_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_upload_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-6c619b3eda26>\u001b[0m in \u001b[0;36mconstruct_date_ranges\u001b[0;34m(path, params, session, start, stop, offset)\u001b[0m\n\u001b[1;32m     27\u001b[0m                                                \u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams_lcl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_upload_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                                \u001b[0;34m,\u001b[0m \u001b[0mtotal_photos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_photos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                                                , offset=offset)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         if VERBOSE >= 2: print(f\"Next suitable range!: {params_lcl['min_upload_date']} to \\\n",
      "\u001b[0;32m<ipython-input-36-74ebbd223551>\u001b[0m in \u001b[0;36mfind_best_date_range\u001b[0;34m(session, params, start, stop, total_photos, offset)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# shifting the date range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mcall_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min_upload_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mtotal_photos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcall_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'photos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mrepeats\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Unexpected EOF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_peek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    xhr_api_call, cookies = get_api_call_string()\n",
    "\n",
    "    parse_api_call(xhr_api_call)\n",
    "\n",
    "    extras = extras.replace('%2C', ',')\n",
    "\n",
    "    added_params = {\n",
    "        \"extras\" : '',\n",
    "        #\"extras\" : extras + ','+ ADD_EXTRAS,\n",
    "        \"per_page\" : 1,\n",
    "        \"api_key\" : api_key,\n",
    "        \"reqId\" : reqId,\n",
    "    }\n",
    "\n",
    "    for each in added_params: params[each] = added_params[each]\n",
    "\n",
    "    spoof_webdriver = False\n",
    "\n",
    "    if spoof_webdriver: ua = UserAgent()\n",
    "\n",
    "    with requests.sessions.Session() as s:\n",
    "        for cookie in cookies:\n",
    "            s.cookies.set(cookie['name'], cookie['value'])\n",
    "        if spoof_webdriver: s.headers['User-Agent'] = str(ua.chrome)\n",
    "\n",
    "    offset = 3    \n",
    "\n",
    "    TEST_RANGE = TAGS[:-2] if TEST and VERBOSE > 3 else TAGS\n",
    "    \n",
    "    date_format = '%Y-%m-%d'\n",
    "    ranges_file = f'./date_ranges_{AFTER_DATE}_{BEFORE_DATE.strftime(date_format)}.csv'\n",
    "    \n",
    "    try:\n",
    "        with open(ranges_file, 'w') as outfile:\n",
    "            outfile.write(\"Search_Term, Uploaded_After, Uploaded_Before, Batch_Size\")\n",
    "    except Exception as e:\n",
    "        print(f\"problem dumping json data: {str(e)}\")\n",
    "    \n",
    "    for term in TEST_RANGE:\n",
    "\n",
    "        params['text'] = term\n",
    "\n",
    "        first_range = True\n",
    "\n",
    "        start = AFTER_DATE\n",
    "        stop = BEFORE_DATE\n",
    "\n",
    "        params['min_upload_date'] = start\n",
    "        params['max_upload_date'] = stop\n",
    "        \n",
    "        if GET_DATES_ONLY:\n",
    "            construct_date_ranges(path=DATA_PATH, params=params, session=s\n",
    "                                  , start=params['min_upload_date']\n",
    "                                  , stop=params['max_upload_date']\n",
    "                                  , offset = offset)\n",
    "        else:\n",
    "            looping_over_date_ranges(path=DATA_PATH, params=params, session=s, start=params['min_upload_date'], stop=params['max_upload_date'], offset = 3)\n",
    "        if VERBOSE >=3:\n",
    "            print(\"\".ljust(120, \"-\"))\n",
    "            print(f\"Finished for term: {term}   in date range : from {start} to {stop}\")\n",
    "            print(\"\".ljust(120, \"-\"))\n",
    "\n",
    "        #time.sleep(random.uniform(COURTESY_SLEEP[0], COURTESY_SLEEP[1]) * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1577682557.453262"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
